# KazanExpress
Основные технчиеские моменты и методы, которые были рассмотрены в процессе выполнения тестового задания, подробно описаны в solution.ipynb.
Здесь я хотел бы рассказать об идеях, которые возникали в процессе работы. Некоторые из них позволили улучшить качество модели,
некоторые не внесли никаких изменений, а некоторые даже ухудшили.

## Идеи и предположения

### Дисбаланс классов

Первое, на что я обратил внимание - это существенный дисбаланс классов. Попытка сделать Downsample, то есть уменьшить число 
экземпляров мажоритарных классов ожидаемо не дало улучшений в работе моделей, а также привело к существенной потере информации.
Следующая идея была применение Upsample, соответсвенно, просто увеличить число экземляров минорных классов, однако, и это не дало
никаких изменений. Последняя идея для выравнивания классов, которую я пробовал применить состояла в следующем: выбрать корпуса
текстов для каждой категории и случайным образом формировать новые названия товаров из всего корпуса слов до выравнивания с числом 
экземпляров мажоритарного класса, относящихся к выбранной категории. Возникшие проблемы: датасет стал настолько огромным, что перестал
помещаться в память, уменьшение числа дополнительных экземпляров приводит к очень долгому обучению, которые не дало никаких значимых 
результатов, также еще одна проблема заключалась в том, что некоторые классы представлепны 2-5 экземплярами с малым числом слов, что
привело просто к дублирвоанию экземляров. На этом я решил оставить идею выравнивания классов. Также сыграло роль общее число классов - 1231.

### Объединение моделей

В процессе обучения модели fasttext, я попробовал предсказывать не крайнюю категорию, а по всему корпусу по порядку определять все категории - предки. 
Данный подход дал интересные результаты, модель fasttext (пробовал только на ней) с высокой точностью предсказывала родительские категории, например, 
первого родителя 0 или -1 (в случае вложенности меньше 6) с точностью 99.8%, второго родителя примерно 99,8 и т.д. Последняя
родительская категория предсказывалась с точностью 88,5%. Тогда я предположил, а почему бы не объединить работу моделей, с помощью fasttext 
предсказывать дополнительные признаки для линейных моделей (все родительские классы), затем стандартизировать, объединять с векторным представлением
и передавать на вход линейной модели. В результате, получилось повысить качество работы линейной модели примерно на 1%, что не дало результат лучше, чем
работа fasttext.

### Отедльная обработка слов-приложений

При выполнении задания обратил внимание на интересный факт, несмотря на высокие показатели работы библиотек для обработки текста, ни один из методов практически не обрабатывает слова - приложения (например, красно-белое), и преврещает их в одно слово (например, краснобелое). поэтому предварительно, слова такого рода были токенизрованы отдельно. Такое решение позволилио увеличить качество модели на итоговой метрике на 1,2%

### Применение тяжелых нейронных сетей (LSTM, BERT)

Также пробовал применить LSTM и BERT, но обучение одной эпохи в среднем занимало около 4-5 часов на GPU без значительных результатов. Поэтому я посчитал, что
для данного задания применение такие нейроннызх сетей нецелесообразно, время работы больше, чем у линейных моделей или fasttext, а полученное качество не является
наилучшим.

### Заключение

Таким образом, была выбрана модель fasttext с подбором параметров, применение которой позволило получить на ивысшие результаты. Для обработки текста наилучшие результаты были получены при лемматизации и отдельной обработки слов-приложений.
